\documentclass[
	english,
	ruledheaders=section,
	class=report,
	thesis={type=bachelor},
	accentcolor=9c,
	custommargins=true,
	marginpar=false,
	%BCOR=5mm,%Bindekorrektur, falls notwendig
	parskip=half-,
	fontsize=11pt,
%	logofile=example-image, %Falls die Logo Dateien nicht vorliegen
]{tudapub}


\usepackage[ngerman, main=english]{babel}
\usepackage[autostyle]{csquotes}

\usepackage{microtype}

\usepackage[backend=biber, style=ieee]{biblatex}  
\addbibresource{bibliboo.bib}


\usepackage{tabularx}  

% \usepackage{booktabs}
% \usepackage{pifont}
\newcommand*{\FeatureTrue}{\ding{52}}
\newcommand*{\FeatureFalse}{\ding{56}}

\begin{document}

\Metadata{
	title=my thesis,
	author=Nina Stewens
}

\title{my thesis}
\subtitle{short description}
\author[N. Stewens]{N. Stewens}
\birthplace{Halle Saale}
\reviewer{Gutachter 1 \and Gutachter 2 \and noch einer}

\department{ce}
\institute{Institut}
\group{Arbeitsgruppe}

\submissiondate{\today}
\examdate{\today}

% Hinweis zur Lizenz: sp√§ter in copy

\maketitle
\affidavit

\tableofcontents

% \include{help}



 \include{introduction}
 %\include{foundations}





\chapter{Foundations}
This chapter serves as an introduction to the used model and theoretical background of this study. 

\section{Natural Language Processing}
Code completion is a natural language problem. The goal is to generate syntactically correct source code. In this section we will be comparing different language models.

train on lots of textual data

generate probability distribution

other works do ast we add more information in hopes of improving results

touch on all model types and explain why not as good

\subsection{Recurrent Neural Networks}
A recurrent neural network makes use of a simple decoder-encoder mechanism. A piece of information(sequence), for example a text or an image is fed into the model and encoded into an SOMETHING. This information is then decoded into a sequence. 
\subsection{transformers}
A transformer is a deep learning model used predominantly for natural language processing (NLP). Other artificial neural networks used for this purpose are recurrent neural networks and convolutional neural network models. Recurrent neural networks



\subsection{Attention}
The attention mechanism assigns a weight to every previous DATAPOINT which enables the model to recognize the important data







 \include{generating_data}
%\include{notes}


\printbibliography
\end{document}